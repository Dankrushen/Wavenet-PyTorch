{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "from wavenet.audiodata import AudioData, AudioLoader\n",
    "from wavenet.models_torch import Model\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x_len = 2**10\n",
    "num_classes = 256\n",
    "num_blocks = 2\n",
    "num_layers = 9\n",
    "num_hidden = 64\n",
    "kernel_size = 2\n",
    "learn_rate = 0.001\n",
    "step_size = 50\n",
    "gamma = 0.5\n",
    "num_workers = 1\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = ['assets/classical.wav']\n",
    "dataset = AudioData(filelist, x_len, classes=num_classes, store_tracks=True)\n",
    "\n",
    "Audio(dataset.tracks[0]['audio'], rate=dataset.tracks[0]['sample_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = AudioLoader(dataset, batch_size=batch_size, \n",
    "                         num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins, outs = dataset.__getitem__(0)\n",
    "print(dataset.datarange)\n",
    "print(ins)\n",
    "print(outs)\n",
    "print(dataset.encoder.decode(ins))\n",
    "print(dataset.label2value(outs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_model = Model(x_len, num_channels=1, num_classes=num_classes, \n",
    "                   num_blocks=num_blocks, num_layers=num_layers,\n",
    "                   num_hidden=num_hidden, kernel_size=kernel_size)\n",
    "\n",
    "wave_model.criterion = nn.CrossEntropyLoss()\n",
    "wave_model.optimizer = optim.Adam(wave_model.parameters(), \n",
    "                                  lr=learn_rate)\n",
    "wave_model.scheduler = optim.lr_scheduler.StepLR(wave_model.optimizer, \n",
    "                                                 step_size=step_size, \n",
    "                                                 gamma=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_model.train(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PyTorchSIIM]",
   "language": "python",
   "name": "conda-env-PyTorchSIIM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
